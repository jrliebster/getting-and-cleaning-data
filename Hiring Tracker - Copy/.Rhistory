View(ComprehensiveHiring2016)
save.image("C:/Users/jules.liebster/Desktop/TNTP/NYCTF/R/R 2016 Comprehensive Hiring.RData")
save.image("C:/Users/jules.liebster/Desktop/TNTP/NYCTF/R/R 2016 Comprehensive Hiring.RData")
ComprehensiveHiring2016$RRSiteCode1.x <- NULL
ComprehensiveHiring2016$RRSiteCode1.x <- NULL
View(ComprehensiveHiring2016)
omprehensiveHiring2016$RRSiteCode1.x <- NULL
ComprehensiveHiring2016$RRCurrentlyFollowUpinFileReview21 <- NULL
ComprehensiveHiring2016$RREverAppSubmitted25 <- NULL
ComprehensiveHiring2016$RREverAppStarted23 <- NULL
ComprehensiveHiring2016$Terminated.from.Job. <- NULL
ComprehensiveHiring2016$Background.Investigation <- NULL
ComprehensiveHiring2016$Dual.Employment.Issue. <- NULL
ComprehensiveHiring2016$Fingerprints.Results.Received. <- NULL
install.packages('plyr')
save.image("C:/Users/jules.liebster/Desktop/TNTP/NYCTF/R/R 2016 Comprehensive Hiring.RData")
count(ComprehensiveHiring2016, 'Renewal.School')
count(ComprehensiveHiring2016, 'Renewal.School'= 'Yes'')
count(ComprehensiveHiring2016, 'Renewal.School'= 'Yes')
ComprehensiveHiring2016['Renewal.School']$freq
x = count(ComprehensiveHiring2016, c('Renewal.School'))
x
x = count(ComprehensiveHiring2016, c('Distirct'))
x
x = count(ComprehensiveHiring2016, c('District'))
c
x
ComprehensiveHiring2016['Renewal.']$freq
x = count(ComprehensiveHiring2016, c('Renewal.'))
x
margin.table(ComprehensiveHiring2016, margin=c(7,9))
margin.table(ComprehensiveHiring2016, margin=c(7,18))
margin.table(ComprehensiveHiring2016, margin=c(7,61))
margin.table(ComprehensiveHiring2016, margin=c(18,61))
count(ComprehensiveHiring2016, 'Renewal.', wt=NULL, sort=TRUE)
count(ComprehensiveHiring2016, 'District.', wt=NULL, sort=TRUE)
count(ComprehensiveHiring2016, 'District.', wt=NULL, sort=FALSE)
count(ComprehensiveHiring2016, 'District.', wt=7, sort=FALSE)
count(ComprehensiveHiring2016, 'District.', wt=7, sort=TRUE)
count(ComprehensiveHiring2016, 'District', 7)
count(ComprehensiveHiring2016, "District")
count(ComprehensiveHiring2016, c("APPID", "District"))
count(ComprehensiveHiring2016, c("RRPrimarySubject8", "District"))
summary(District)
summary(ComprehensiveHiring2016$District)
head(ComprehensiveHiring2016$District)
levels(ComprehensiveHiring2016$District)
ComprehensiveHiring2016$RRSummativePSTOutcome53 <- NULL
ComprehensiveHiring2016$RRDateStartteaching57 <- NULL
ComprehensiveHiring2016$RRStartTeaching56 <- NULL
hist(ComprehensiveHiring2016$District)
plot(ComprehensiveHiring2016$District, ComprehensiveHiring2016$RRPrescreenerAssignedSubject7)
separate(ComprehensiveHiring2016, BQ.Submitted., c("Submitted.Month", "Submitted.Day", "Submitted.Year"), sep = "/")
View(ComprehensiveHiring2016)
library(stringr)
library("stringi", lib.loc="~/R/win-library/3.3")
ComprehensiveHiring2016$Race[ComprehensiveHiring2016$Race == ""] <- NA
View(ComprehensiveHiring2016)
save.image("C:/Users/jules.liebster/Desktop/TNTP/NYCTF/R/R 2016 Comprehensive Hiring.RData")
devtools::install_github("sfirke/janitor", ref = "split_up_adornments")
# Initialize knitr, set options, load packages
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
detach("package:pacman", unload=TRUE)
detach("package:devtools", unload=TRUE)
devtools::install_github("sfirke/janitor", ref = "split_up_adornments")
devtools :: session_info()
install.packages("devtools")
install.packages("devtools")
install.packages("bindrcpp")
install.packages("dplyr")
devtools::install_github("sfirke/janitor", ref = "split_up_adornments")
# Initialize knitr, set options, load packages
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
tntp_ratings <- read_excel("partner program status tracker 5-18-17.xlsx", sheet = "ACE") %>%
select(participantExternalId, cultureOfLearningScore:overallObservationScore, round) %>%
clean_names()
library(tntpr)
install.packages("tntpr")
library(tntpr)
install.packages("tntpr")
library(devtools) # for install_git()
if(!require("tntpr")) install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git")
library(tntpr)
library(tntpr)
install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git")
# Initialize knitr, set options, load packages
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
install.packages("extrafontdb")
install.packages("tntpr")
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
# Initialize knitr, set options, load packages
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
install.packages("extrafontdb")
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
library(tntpr)
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
install.packages("Rttf2pt1")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
install.packages("Rttf2pt1")
install.packages("htmlwidgets")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
library(tntpr)
library(tntpr)
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
tntp_ratings <- read_excel("partner program status tracker 5-18-17.xlsx", sheet = "ACE") %>%
select(participantExternalId, cultureOfLearningScore:overallObservationScore, round) %>%
clean_names()
# Average the competencies to produce an overall score
catr_means <- catr %>%
select(-CA, -CS, -TC, -Sm) %>%
gather(measure, value, TP:RD) %>%
mutate(value = as.numeric(value)) %>%
group_by(round, Teacher) %>%
summarise(overall_mean = mean(value, na.rm = TRUE)) %>% # there's one teacher in the 1st round who is missing a rating just on the RD indicator; thus na.rm = TRUE
ungroup() %>%
mutate(adj_catr_means_buckets = case_when( # these cut points come from a deck Megan Goodrich emailed; modeled off of DC IMPACT.  I confirmed this approach w/ Megan.
overall_mean < 2 ~ 1,
overall_mean < 2.5 ~ 2,
overall_mean < 3 ~ 3,
overall_mean < 3.5 ~ 4,
overall_mean <= 4 ~ 5,
TRUE ~ 10000 # there should not be anything possible above 4
)
)
tntp_means <- tntp_ratings %>%
select(Teacher = participantexternalid, overall_mean = overallobservationscore, round)
# Rename variables and combine
all_rounds <- bind_rows(
catr_means %>%
select(rating = adj_catr_means_buckets, round) %>%
mutate(source = "CATR"),
tntp_means %>%
select(rating = overall_mean, round) %>%
mutate(source = "TNTP", round = parse_number(round))
) %>%
mutate(
rating_categorical_label = if_else(
source %in% "TNTP", # use these cutoff scores for those whose obs averages come from the TNTP Core rubric
as.character(cut(rating, breaks = c(1, 2, 2.8, 3.6, 4.3, 5.01), labels = c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful"), right = FALSE)),
if_else(source %in% c("CATR"), # these were bucketed out to categories in the case_when() statement above; just convert to words:
c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful")[rating], # this maps these words to the integers 1:5
as.character(NA))
),
rating_categorical_label = ordered(rating_categorical_label, levels = c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful")) # order as a factor for printing in the correct order
)
crosstabs <- all_rounds %>%
tabyl(source, rating_categorical_label, round, show_na = FALSE) %>% # this line will only work if you install a development version of janitor:
# install_github("sfirke/janitor", ref = "split_up_adornments")
purrr::map(adorn_percentages, "row") # convert each entry in the list to percentages
crosstabs[[1]] %>% mutate(Round = "Round 1")  %>% select(Round, everything()) %>% kable()
crosstabs[[2]] %>% mutate(Round = "Round 2")  %>% select(Round, everything()) %>% kable()
crosstabs[[3]] %>% mutate(Round = "Round 3")  %>% select(Round, everything()) %>% kable()
crosstabs[[4]] %>% mutate(Round = "Round 4")  %>% select(Round, everything()) %>% kable()
library(tntpr)
library("tntpr", lib.loc="~/R/win-library/3.3")
devtools::install_github("sfirke/janitor", ref = "split_up_adornments")
devtools::install_github("sfirke/janitor", ref = "split_up_adornments")
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
install.packages("Rttf2pt1")
install.packages("htmlwidgets")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
library(tntpr)
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
tntp_ratings <- read_excel("partner program status tracker 5-18-17.xlsx", sheet = "ACE") %>%
select(participantExternalId, cultureOfLearningScore:overallObservationScore, round) %>%
clean_names()
# Average the competencies to produce an overall score
catr_means <- catr %>%
select(-CA, -CS, -TC, -Sm) %>%
gather(measure, value, TP:RD) %>%
mutate(value = as.numeric(value)) %>%
group_by(round, Teacher) %>%
summarise(overall_mean = mean(value, na.rm = TRUE)) %>% # there's one teacher in the 1st round who is missing a rating just on the RD indicator; thus na.rm = TRUE
ungroup() %>%
mutate(adj_catr_means_buckets = case_when( # these cut points come from a deck Megan Goodrich emailed; modeled off of DC IMPACT.  I confirmed this approach w/ Megan.
overall_mean < 2 ~ 1,
overall_mean < 2.5 ~ 2,
overall_mean < 3 ~ 3,
overall_mean < 3.5 ~ 4,
overall_mean <= 4 ~ 5,
TRUE ~ 10000 # there should not be anything possible above 4
)
)
tntp_means <- tntp_ratings %>%
select(Teacher = participantexternalid, overall_mean = overallobservationscore, round)
# Rename variables and combine
all_rounds <- bind_rows(
catr_means %>%
select(rating = adj_catr_means_buckets, round) %>%
mutate(source = "CATR"),
tntp_means %>%
select(rating = overall_mean, round) %>%
mutate(source = "TNTP", round = parse_number(round))
) %>%
mutate(
rating_categorical_label = if_else(
source %in% "TNTP", # use these cutoff scores for those whose obs averages come from the TNTP Core rubric
as.character(cut(rating, breaks = c(1, 2, 2.8, 3.6, 4.3, 5.01), labels = c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful"), right = FALSE)),
if_else(source %in% c("CATR"), # these were bucketed out to categories in the case_when() statement above; just convert to words:
c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful")[rating], # this maps these words to the integers 1:5
as.character(NA))
),
rating_categorical_label = ordered(rating_categorical_label, levels = c("Ineffective", "Minimally Effective", "Developing", "Proficient", "Skillful")) # order as a factor for printing in the correct order
)
crosstabs <- all_rounds %>%
tabyl(source, rating_categorical_label, round, show_na = FALSE) %>% # this line will only work if you install a development version of janitor:
# install_github("sfirke/janitor", ref = "split_up_adornments")
purrr::map(adorn_percentages, "row") # convert each entry in the list to percentages
crosstabs[[1]] %>% mutate(Round = "Round 1")  %>% select(Round, everything()) %>% kable()
crosstabs[[2]] %>% mutate(Round = "Round 2")  %>% select(Round, everything()) %>% kable()
crosstabs[[3]] %>% mutate(Round = "Round 3")  %>% select(Round, everything()) %>% kable()
crosstabs[[4]] %>% mutate(Round = "Round 4")  %>% select(Round, everything()) %>% kable()
all_rounds %>%
group_by(source, round) %>%
summarise(mean_adj_rating = mean(rating, na.rm = TRUE),
n = n(),
n_ratings = sum(!is.na(rating))) %>%
kable()
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
install.packages("Rttf2pt1")
install.packages("htmlwidgets")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
chooseCRANmirror(graphics=FALSE, ind=1)
install.packages("extrafontdb")
# Initialize knitr, set options, load packages
install.packages("extrafontdb")
install.packages("Rttf2pt1")
install.packages("htmlwidgets")
if(!suppressPackageStartupMessages(require("pacman"))) install.packages("pacman"); library(pacman)
if(!suppressPackageStartupMessages(require("tntpr"))) { p_load(devtools); install_git("https://tools.tntp.org/bitbucket/scm/ct/tntpr.git") }
p_load(knitr, tntpr, readr, purrr, readxl, dplyr, magrittr, ggplot2, stringr, devtools, scales, janitor, tidyr)
set_data_memo_formatting() # sets some common knitr chunk options
chooseCRANmirror(graphics=FALSE, ind=1)
# function to treat each tab of the CATR data, snagged from Google Sheets
# data source: https://docs.google.com/spreadsheets/d/1AiDxXoMXgHs0fRUbnjeqkK5DOneFCKeJ3LGcjpsu6gQ/edit#gid=2030130540, copied on 6-22-2017 into the below Excel file
read_catr_data <- function(round_no){
catr <- read_excel("CATR data from Google Sheets SY 16-17.xlsx", sheet = paste0("Round", round_no))
names(catr) <- catr[1, ] # get col names, which are in the first row
catr[catr == "No data"] <- NA # this value should be made NA so that remove_empty_cols works on the round 1 data
catr <- catr[-1, ] %>% # drop first row that had names and any unused cols at the end
remove_empty_cols()
catr$round <- round_no
catr <- filter(catr, !is.na(TP)) # remove rows where teachers did not get a score - there are no missing values of TP in the 4 rounds, I confirmed manually
catr
}
catr <- bind_rows(
lapply(1:4, read_catr_data)
)
tntp_ratings <- read_excel("partner program status tracker 5-18-17.xlsx", sheet = "ACE") %>%
select(participantExternalId, cultureOfLearningScore:overallObservationScore, round) %>%
clean_names()
setwd("C:/Users/jules.liebster/Desktop/TNTP/NYCTF/R/Hiring Tracker - Copy")
#load packages
library(pacman)
p_load(readxl, readr, dplyr, janitor, tidyr, stringr, ggplot2, lubridate)
#upload datasets (Hiring information report from TT2, comprehensive report, and NHF from DOE client)
fellow_hiring <- read_csv("hiringinformation.csv") %>%
clean_names()
new_hire_file <- read_csv("fellowNHF.csv") %>%
clean_names()
comprehensive <- read_csv("comprehensive.csv") %>%
clean_names()
#rename phone number column in fellow_hiring and new_hire_file
names(fellow_hiring)[names(fellow_hiring) == "rrphonenumber18"] <- "phone_number"
names(new_hire_file)[names(new_hire_file) == "phone"] <- "phone_number"
names(comprehensive)[names(comprehensive) == "rrprimaryphone7"] <- "phone_number"
##need to remove any characters that are not numbers from the phone number field, this is trailing (look for code that removes special characters from inside vector)
trim.trailing <- function (x) sub("\\-s+$", "", x)
fellow_hiring$phone_number <- trim.trailing(fellow_hiring$phone_number)
fellow_hiring$phone_number <- gsub("[[:punct:]]", "", fellow_hiring$phone_number)
comprehensive$phone_number <- trim.trailing(comprehensive$phone_number)
comprehensive$phone_number <- gsub("[[:punct:]]", "", comprehensive$phone_number)
new_hire_file$phone_number <- trim.trailing(new_hire_file$phone_number)
new_hire_file$phone_number <- gsub("[[:punct:]]", "", new_hire_file$phone_number)
#change names of app user id field to match so I am able to join the comprehensive and fellow hiring datasets
names(fellow_hiring)[names(fellow_hiring) == "rrappuserid1"] <- "appid"
names(comprehensive)[names(comprehensive) == "rrappuserid3"] <- "appid"
#join comprehensive and fellow hiring
fellow_hiring <- left_join(fellow_hiring, comprehensive, by = "appid")
names(fellow_hiring)[names(fellow_hiring) == "phone_number.x"] <- "phone_number"
#next, need to remove unnecessary variables, like those related to schgeudling interviews
#keep only useful columns df <- subset(df, select = c(a,c))
#change names of school code field to DBN so I am able to join the renewal crosswalk and fellow hiring datasets, remove DBN NA
names(fellow_hiring)[names(fellow_hiring) == "rrschoolcode5"] <- "DBN"
fellow_hiring <- filter(fellow_hiring, !is.na(DBN))
#change POCNonWhite column to name POC
names(fellow_hiring)[names(fellow_hiring) == "rrpocnonehite63"] <- "POC"
#change blank cases in Cert.Description column to NA
new_hire_file$Cert.Description[new_hire_file$Cert.Description == ""] <- NA
#change blank cases in Lic.Desc column to NA
new_hire_file$Lic.Desc[new_hire_file$Lic.Desc == ""] <- NA
#join fellow_hiring and new_hire_file by phone number
new_hire_file$phone_number <- as.character(new_hire_file$phone_number)
all_fellow_hiring <- left_join(new_hire_file, fellow_hiring, by = "phone_number")
all_fellow_hiring[all_fellow_hiring$renewal_school="NO"]
View(all_fellow_hiring)
all_fellow_hiring[all_fellow_hiring$renewal_school=="NO"]
all_fellow_hiring[all_fellow_hiring$district=="9"]
all_fellow_hiring[all_fellow_hiring$district="9"]
all_fellow_hiring[all_fellow_hiring$district==9]
all_fellow_hiring[all_fellow_hiring$district=="9",]
all_fellow_hiring[,list(sum("district"))]
all_fellow_hiring[,table("district")]
all_fellow_hiring[, .N,by=district]
all_fellow_hiring[, .N,by="district"]
all_fellow_hiring[, .N, by=district]
all_fellow_hiring[, .N,by=all_fellow_hiring$district]
load(data.table)
p_load(readxl, readr, dplyr, janitor, tidyr, stringr, ggplot2, lubridate, data.table)
setkey(all_fellow_hiring, district)
swirl()
library(swirl)
swirl()
2
0
0
swirl()
swirl()
2
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
package_version("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
select(-5:20)
(-5:20)
-(5:20)
select(cran, -(X:size))
(cran, package == "swirl")
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version =< "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version)0
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran, ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size*10)
mutate(cran3, correct_size= size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df("mydf")
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(cran, mean(size))
summarize(by_package, mean(size))
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- (pack_sum, unique > 465)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
